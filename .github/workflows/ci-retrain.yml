name: CI - Retrain & Build Docker Image

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:

env:
  WORKING_DIR: "MLProject"

jobs:
  retrain-and-build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache pip + MLproject env
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/pip
            .mlflow_venv_cache
          key: mlproject-${{ hashFiles('MLProject/requirements.txt') }}-${{ runner.os }}

      - name: Install MLflow
        run: pip install --upgrade pip "mlflow[extras]"

      - name: Force Local Tracking URI
        run: echo "MLFLOW_TRACKING_URI=file:./mlruns" >> $GITHUB_ENV

      - name: Verify Data File
        run: |
          cd ${{ env.WORKING_DIR }}
          ls -la data/
          [ -f "data/preprocessing_objects.pkl" ] || (echo "ERROR: preprocessing_objects.pkl missing!" && exit 1)

      - name: Run Training via MLproject (pip + venv â†’ 100% works on CI)
        run: |
          cd ${{ env.WORKING_DIR }}
          echo "Running MLproject with python_env (requirements.txt)"

          mlflow run . \
            -P model_name=all \
            --experiment-name=Heart_Disease_Classification \
            --env-manager=local   # penting: paksa local venv, bukan conda

      - name: Get Latest Run Info
        id: runinfo
        run: |
          cd ${{ env.WORKING_DIR }}
          python - <<EOF
          import mlflow, os
          client = mlflow.MlflowClient(tracking_uri="file:./mlruns")
          exp = client.get_experiment_by_name("Heart_Disease_Classification")
          runs = client.search_runs(exp.experiment_id, order_by=["start_time DESC"], max_results=1)
          run = runs[0]
          best = run.data.params.get("best_model_name", "Unknown")
          print(f"run_id={run.info.run_id}", file=open(os.environ["GITHUB_OUTPUT"], "a"))
          print(f"best_model={best}", file=open(os.environ["GITHUB_OUTPUT"], "a"))
          print(f"Latest Run: {run.info.run_id} | Best: {best}")
          EOF

      - name: Setup Docker
        uses: docker/setup-buildx-action@v3

      - name: Login Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build & Push Docker Image
        env:
          IMAGE: ${{ secrets.DOCKER_USERNAME }}/heart-disease-model
          RUN_ID: ${{ steps.runinfo.outputs.run_id }}
          BEST: ${{ steps.runinfo.outputs.best_model }}
        run: |
          cd ${{ env.WORKING_DIR }}
          export MLFLOW_TRACKING_URI=file:./mlruns

          if mlflow models build-docker \
               -m "runs:/$RUN_ID/best_model" \
               -n "$IMAGE:latest" \
               --enable-mlserver; then
            echo "MLflow native build OK"
          else
            echo "Fallback manual Dockerfile"
            cat > Dockerfile <<EOF
          FROM python:3.12-slim
          RUN pip install --no-cache-dir mlserver mlserver-mlflow scikit-learn pandas numpy
          COPY data/best_model_${BEST}.pkl /app/model.pkl
          COPY mlruns /app/mlruns
          WORKDIR /app
          ENV MLSERVER_MODEL_URI=/app/model.pkl
          ENV MLSERVER_MODEL_NAME=heart-disease
          EXPOSE 8080
          CMD ["mlserver", "start", "/app"]
          EOF
            docker build -t $IMAGE:latest .
          fi

          TAG=$(date +%Y%m%d%H%M)
          docker tag $IMAGE:latest $IMAGE:$TAG
          docker tag $IMAGE:latest $IMAGE:${RUN_ID:0:8}

          docker push $IMAGE:latest
          docker push $IMAGE:$TAG
          docker push $IMAGE:${RUN_ID:0:8}

          echo "IMAGE_LATEST=$IMAGE:latest" >> $GITHUB_ENV

      - name: Test Image
        run: |
          docker run -d -p 5000:8080 --name test ${{ env.IMAGE_LATEST }}
          sleep 15
          curl -f http://localhost:5000/ping || echo "Warning: ping not available (normal for MLServer)"
          docker logs test
          docker stop test && docker rm test

      - name: Summary
        run: |
          echo "## Pipeline Success!" >> $GITHUB_STEP_SUMMARY
          echo "- Best Model: **${{ steps.runinfo.outputs.best_model }}**" >> $GITHUB_STEP_SUMMARY
          echo "- Image: \`${{ env.IMAGE_LATEST }}\`" >> $GITHUB_STEP_SUMMARY
